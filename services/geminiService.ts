// FIX: This file was empty. Implemented Gemini service for virtual try-on.
import { GoogleGenAI, Modality, Part } from "@google/genai";
import { Product } from '../types';

const apiKey = process.env.API_KEY;
if (!apiKey) {
    console.error("VITE_GEMINI_API_KEY is not set. The app will not function correctly.");
    throw new Error("VITE_GEMINI_API_KEY is not defined. Please set it in your deployment environment variables.");
}
const ai = new GoogleGenAI({ apiKey });


// Helper function to fetch an image from a URL and convert it to a base64 string
const urlToBase64 = async (url: string): Promise<{ data: string, mimeType: string }> => {
    // Note: This may fail in a browser environment if the image server doesn't have permissive CORS headers.
    // A server-side proxy may be needed in a production environment.
    const response = await fetch(url);
    if (!response.ok) {
        throw new Error(`Failed to fetch image from ${url}: ${response.statusText}`);
    }
    const blob = await response.blob();
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => {
            if (reader.error) {
                return reject(reader.error);
            }
            const base64Data = (reader.result as string).split(',')[1];
            resolve({ data: base64Data, mimeType: blob.type });
        };
        reader.onerror = (error) => reject(error);
        reader.readAsDataURL(blob);
    });
};

export const generateTryOnImage = async (
    personImageBase64: string,
    personImageMimeType: string,
    products: Product[] // Changed to accept an array of products
): Promise<string> => {
    try {
        const personImagePart: Part = {
            inlineData: {
                data: personImageBase64,
                mimeType: personImageMimeType,
            },
        };

        // Fetch and convert all product images in parallel
        const productPromises = products.map(product => urlToBase64(product.imageUrl));
        const productImages = await Promise.all(productPromises);

        const productImageParts: Part[] = productImages.map(image => ({
            inlineData: {
                data: image.data,
                mimeType: image.mimeType,
            },
        }));

        // Create a dynamic prompt for multiple items
        const productNames = products.map(p => `"${p.name}"`).join(', ');
        const textPart: Part = {
            text: `Take the clothing items from the following images and realistically place them on the person in the first image to create a complete outfit. The clothing items are: ${productNames}. The person should be wearing all the items, layered correctly (e.g., a shirt under a jacket). Maintain the original background and the person's pose.`,
        };


        // FIX: Use the correct model and parameters for image editing as per guidelines
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image-preview',
            contents: {
                parts: [
                    personImagePart,
                    ...productImageParts, // Include all product images
                    textPart,
                ],
            },
            config: {
                // FIX: responseModalities must include both IMAGE and TEXT
                responseModalities: [Modality.IMAGE, Modality.TEXT],
            },
        });
        
        // FIX: Correctly extract the generated image from the response
        if (response.candidates && response.candidates[0].content && response.candidates[0].content.parts) {
            for (const part of response.candidates[0].content.parts) {
                if (part.inlineData) {
                    return part.inlineData.data;
                }
            }
        }

        throw new Error("No image was generated by the model.");

    } catch (error) {
        console.error("Error generating virtual try-on image:", error);
        throw new Error("Failed to generate virtual try-on image. Please try again.");
    }
};